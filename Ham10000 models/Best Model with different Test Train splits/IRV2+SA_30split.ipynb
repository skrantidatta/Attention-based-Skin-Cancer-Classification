{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5X3ASNLkv3Y",
    "outputId": "c70128ac-abd1-48af-bb8f-8b88c191b377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTi0RAUGEfoM",
    "outputId": "6645936f-fa1e-4b83-c22c-fcfb74d1cbda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "filename=\"/content/drive/My Drive/HAM10000.zip\"\n",
    "with ZipFile(filename,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Aa36bMKLze3z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import callbacks \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from  matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lnzRzk7e44HL",
    "outputId": "06462d24-593c-48fe-b590-165f654e9ace"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv('/content/drive/MyDrive/HAM10000_metadata.csv')\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qlR6SjeEzXsm"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join('HAM10000', 'train_dir')\n",
    "test_dir = os.path.join('HAM10000', 'test_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "_IFqPgUu5jPj",
    "outputId": "5e85918d-ff71-429a-ecf0-747297fd47e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesion_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HAM_0000000</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000001</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000002</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000004</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  dx  dx_type  age  sex  localization\n",
       "lesion_id                                                 \n",
       "HAM_0000000         2   2        2    2    2             2\n",
       "HAM_0000001         1   1        1    1    1             1\n",
       "HAM_0000002         3   3        3    3    3             3\n",
       "HAM_0000003         1   1        1    1    1             1\n",
       "HAM_0000004         1   1        1    1    1             1"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = data_pd.groupby('lesion_id').count()\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QjMQNZRI2xl7"
   },
   "outputs": [],
   "source": [
    "df_count = df_count[df_count['dx'] == 1]\n",
    "df_count.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NeVfs-Ly95gs"
   },
   "outputs": [],
   "source": [
    "def duplicates(x):\n",
    "    unique = set(df_count['lesion_id'])\n",
    "    if x in unique:\n",
    "        return 'no' \n",
    "    else:\n",
    "        return 'duplicates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2WZZRSzO5v8t",
    "outputId": "b641fb4e-0aef-42ae-a78e-be38f5e4b268"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization is_duplicate\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   duplicates\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   duplicates\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   duplicates\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   duplicates\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   duplicates"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd['is_duplicate'] = data_pd['lesion_id'].apply(duplicates)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3BhGlAv0yAHu"
   },
   "outputs": [],
   "source": [
    "df_count = data_pd[data_pd['is_duplicate'] == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y3ndAO_Ex5fb"
   },
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df_count, test_size=0.3, stratify=df_count['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T7w2kYUdNkjX",
    "outputId": "7f0c23f5-7c30-40c8-8795-64b8596bc434"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>train_test_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  ... localization  is_duplicate train_test_split\n",
       "0  HAM_0000118  ISIC_0027419  bkl  ...        scalp    duplicates            train\n",
       "1  HAM_0000118  ISIC_0025030  bkl  ...        scalp    duplicates            train\n",
       "2  HAM_0002730  ISIC_0026769  bkl  ...        scalp    duplicates            train\n",
       "3  HAM_0002730  ISIC_0025661  bkl  ...        scalp    duplicates            train\n",
       "4  HAM_0001466  ISIC_0031633  bkl  ...          ear    duplicates            train\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identify_trainOrtest(x):\n",
    "    test_data = set(test_df['image_id'])\n",
    "    if str(x) in test_data:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "#creating train_df\n",
    "data_pd['train_test_split'] = data_pd['image_id'].apply(identify_trainOrtest)\n",
    "train_df = data_pd[data_pd['train_test_split'] == 'train']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FPySEG1m58pu",
    "outputId": "39d99b1a-4f11-47a9-f6e6-7be3ea38cbc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>HAM_0000019</td>\n",
       "      <td>ISIC_0025396</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>HAM_0005675</td>\n",
       "      <td>ISIC_0030814</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>HAM_0003894</td>\n",
       "      <td>ISIC_0025560</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>HAM_0004523</td>\n",
       "      <td>ISIC_0029984</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>HAM_0004499</td>\n",
       "      <td>ISIC_0027331</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>neck</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id      image_id  dx  ...     sex     localization is_duplicate\n",
       "8731  HAM_0000019  ISIC_0025396  nv  ...  female             back           no\n",
       "3781  HAM_0005675  ISIC_0030814  nv  ...  female  lower extremity           no\n",
       "4562  HAM_0003894  ISIC_0025560  nv  ...  female            trunk           no\n",
       "3739  HAM_0004523  ISIC_0029984  nv  ...  female  lower extremity           no\n",
       "3623  HAM_0004499  ISIC_0027331  nv  ...    male             neck           no\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ja7jQJQb39wi"
   },
   "outputs": [],
   "source": [
    "# Image id of train and test images\n",
    "train_list = list(train_df['image_id'])\n",
    "test_list = list(test_df['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBJgBAjP13q5",
    "outputId": "f084923e-e467-4195-c7eb-061c673a433c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1655"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEChk1DK-H8Z",
    "outputId": "3aeec296-63a7-41a2-da8e-ed199e907828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8360"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PIoMqylGAYYZ"
   },
   "outputs": [],
   "source": [
    "# Set the image_id as the index in data_pd\n",
    "data_pd.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ja_PtDYyDPMM"
   },
   "outputs": [],
   "source": [
    "os.mkdir(train_dir)\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PsoqCvNsgmHP"
   },
   "outputs": [],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9KYMTQugCmRR"
   },
   "outputs": [],
   "source": [
    "for i in targetnames:\n",
    "  directory1=train_dir+'/'+i\n",
    "  directory2=test_dir+'/'+i\n",
    "  os.mkdir(directory1)\n",
    "  os.mkdir(directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GL9vFa3X-ty1"
   },
   "outputs": [],
   "source": [
    "for image in train_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = data_pd.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join('HAM10000', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(train_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hwbKrEzJ_if2"
   },
   "outputs": [],
   "source": [
    "for image in test_list:\n",
    "\n",
    "    file_name = image+'.jpg'\n",
    "    label = data_pd.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join('HAM10000', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(test_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4W8hmE2OHjQa",
    "outputId": "603e2f6f-e7f4-41d4-e8e8-9c8457db05f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 282 images belonging to 1 classes.\n",
      "Found 461 images belonging to 1 classes.\n",
      "Found 967 images belonging to 1 classes.\n",
      "Found 103 images belonging to 1 classes.\n",
      "Found 1044 images belonging to 1 classes.\n",
      "Found 5380 images belonging to 1 classes.\n",
      "Found 123 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "\n",
    "# Augmenting images and storing them in temporary directories \n",
    "for img_class in targetnames:\n",
    "\n",
    "    #creating temporary directories\n",
    "    # creating a base directory\n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    # creating a subdirectory inside the base directory for images of the same class\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    img_list = os.listdir('HAM10000/train_dir/' + img_class)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir \n",
    "    for file_name in img_list:\n",
    "\n",
    "        # path of source image in training directory\n",
    "        source = os.path.join('HAM10000/train_dir/' + img_class, file_name)\n",
    "\n",
    "        # creating a target directory to send images \n",
    "        target = os.path.join(img_dir, file_name)\n",
    "\n",
    "        # copying the image from the source to target file\n",
    "        shutil.copyfile(source, target)\n",
    "\n",
    "    # Temporary augumented dataset directory.\n",
    "    source_path = aug_dir\n",
    "\n",
    "    # Augmented images will be saved to training directory\n",
    "    save_path = 'HAM10000/train_dir/' + img_class\n",
    "\n",
    "    # Creating Image Data Generator to augment images\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "\n",
    "    )\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(source_path,save_to_dir=save_path,save_format='jpg',target_size=(299, 299),batch_size=batch_size)\n",
    "\n",
    "    # Generate the augmented images\n",
    "    aug_images = 8000 \n",
    "\n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((aug_images - num_files) / batch_size))\n",
    "\n",
    "    # creating 8000 augmented images per class\n",
    "    for i in range(0, num_batches):\n",
    "        images, labels = next(aug_datagen)\n",
    "\n",
    "    # delete temporary directory \n",
    "    shutil.rmtree('aug_dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wNisha_gM3_Z"
   },
   "outputs": [],
   "source": [
    "train_path = 'HAM10000/train_dir'\n",
    "test_path = 'HAM10000/test_dir'\n",
    "batch_size =16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zhQWqdRN79B3"
   },
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9_8FvOO7Rtu",
    "outputId": "597054a4-505c-4227-c2f2-f9f3127d8baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 51010 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 1655 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 299\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AbwfHcsOPKYB"
   },
   "outputs": [],
   "source": [
    "#Soft Attention\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class SoftAttention(Layer):\n",
    "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
    "        self.channels=int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "\n",
    "        \n",
    "        super(SoftAttention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.i_shape = input_shape\n",
    "\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
    "    \n",
    "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "\n",
    "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "        \n",
    "\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                        initializer='he_uniform',\n",
    "                                        name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_conv3d')\n",
    "\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        exp_x = K.expand_dims(x,axis=-1)\n",
    "\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                     kernel=self.kernel_conv3d,\n",
    "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d,\n",
    "                        self.bias_conv3d)\n",
    "        conv3d = kl.Activation('relu')(conv3d)\n",
    "\n",
    "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
    "\n",
    "        \n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
    "\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1) \n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)       \n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
    "   \n",
    "            x_exp = K.expand_dims(x,axis=-2)\n",
    "   \n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])   \n",
    "  \n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
    "\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
    "\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
    "\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])   \n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u,x])\n",
    "        else:\n",
    "            o = u\n",
    "        \n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
    "\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(SoftAttention,self).get_config()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrlJwba5By1A",
    "outputId": "ce70f4c1-d8b6-44c2-98c6-922a4b66e8cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "225214464/225209952 [==============================] - 10s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "irv2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=\"softmax\",\n",
    "\n",
    ")\n",
    "\n",
    "# Excluding the last 28 layers of the model.\n",
    "conv = irv2.layers[-28].output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTFfWfqXVjsf"
   },
   "source": [
    "Soft Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exrVTX_uVYPi"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R13YR5JxVpOg"
   },
   "outputs": [],
   "source": [
    "\n",
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=irv2.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clgALKTDkVC_",
    "outputId": "f2a6aea3-c755-4ab9-849d-69af2e327913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 96)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 48)   13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 64)   27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 48)   13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 48)   13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 48)   144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 64)   27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 64)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 48)   13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 35, 35, 48)   144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 48)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 64)   27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 48)   13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 48)   144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 48)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 64)   27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 35, 35, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 64)   192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 48)   13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 35, 35, 48)   144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 48)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 64)   27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 35, 35, 64)   192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 48)   13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 35, 35, 48)   144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 48)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 64)   27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 35, 35, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 35, 35, 64)   192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 48)   13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 35, 35, 48)   144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 35, 35, 48)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 32)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 64)   27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 35, 35, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 48)   13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 35, 35, 48)   144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 35, 35, 48)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 32)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 64)   27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 35, 35, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 35, 35, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 35, 35, 32)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 35, 35, 64)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 48)   13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 35, 35, 48)   144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 35, 35, 48)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 64)   27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 35, 35, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 35, 35, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 35, 35, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 35, 35, 64)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 35, 35, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 35, 35, 256)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 256)  589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 384)  884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 384)  1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 384)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 384)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 160)  143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 160)  480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 160)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 192)  215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 128)  384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 160)  143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 160)  480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 160)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 192)  215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 192)  576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 192)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 128)  384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 160)  143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 160)  480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 160)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 192)  215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 192)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 128)  384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 128)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 160)  143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 160)  480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 160)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 192)  215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 192)  576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 192)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 128)  384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 128)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 160)  143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 160)  480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 160)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 128)  384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 160)  143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 160)  480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 160)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 17, 17, 128)  384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 128)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 160)  143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 160)  480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 160)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 192)  215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 17, 17, 192)  576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 192)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 128)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 160)  143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 17, 17, 160)  480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 160)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 192)  215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 17, 17, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 192)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 160)  143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 17, 17, 160)  480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 160)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 192)  215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 17, 17, 192)  576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 192)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 128)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 17, 17, 160)  143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 17, 17, 160)  480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 17, 17, 160)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 17, 17, 192)  215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 17, 17, 192)  576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 17, 17, 192)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 17, 17, 128)  384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 128)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 17, 17, 160)  143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 17, 17, 160)  480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 17, 17, 160)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 17, 17, 192)  215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 17, 17, 192)  576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 17, 17, 192)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 17, 17, 128)  384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 17, 17, 160)  143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 17, 17, 160)  480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 17, 17, 160)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 17, 17, 192)  215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 17, 17, 192)  576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 17, 17, 192)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 160)  143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 17, 17, 160)  480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 160)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 192)  215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 160)  143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 17, 17, 160)  480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 160)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 192)  215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 17, 17, 192)  576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 192)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 17, 17, 128)  384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 128)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 160)  143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 17, 17, 160)  480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 160)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 17, 17, 192)  215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 17, 17, 128)  384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 17, 17, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 17, 17, 160)  143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 17, 17, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 17, 17, 192)  576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 17, 17, 192)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 17, 17, 128)  384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 17, 17, 128)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 17, 17, 160)  143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 17, 17, 128)  384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 17, 17, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 17, 17, 160)  143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 17, 17, 128)  384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 17, 17, 128)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 17, 17, 160)  143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 17, 17, 192)  215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 17, 17, 192)  576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 17, 17, 192)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 17, 17, 128)  384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 128)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 160)  143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 17, 17, 160)  480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 160)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 17, 17, 192)  215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 17, 17, 256)  768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 17, 17, 256)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 288)  663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 17, 17, 256)  768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 17, 17, 256)  768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 17, 17, 288)  864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 256)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 17, 17, 256)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 288)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 8, 8, 384)    884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 288)    663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 320)    829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 8, 8, 384)    1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 8, 8, 288)    864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 8, 8, 320)    960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 8, 8, 384)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 8, 8, 288)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 8, 8, 320)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 224)    129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 224)    672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 224)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 256)    172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 8, 8, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 256)    768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 8, 8, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 256)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 224)    129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 224)    672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 224)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 256)    172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 256)    768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 256)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 224)    129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 8, 8, 224)    672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 224)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 256)    172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 192)    576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 8, 8, 256)    768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 192)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 256)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 224)    129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 8, 8, 224)    672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 224)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 256)    172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 8, 8, 192)    576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 8, 8, 256)    768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 192)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 256)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 224)    129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 8, 8, 224)    672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 224)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 256)    172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 8, 8, 256)    768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 256)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 224)    129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 224)    672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 224)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 256)    172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 8, 8, 192)    576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 256)    768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 192)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 256)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 8, 8, 224)    129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 8, 8, 224)    672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 224)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 8, 8, 256)    172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 8, 8, 256)    768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 256)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 8, 8, 224)    129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 8, 8, 224)    672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 224)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 8, 8, 256)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 8, 8, 192)    576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 8, 8, 256)    768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 192)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 256)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 8, 8, 192)    576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "soft_attention (SoftAttention)  [(None, 8, 8, 192),  27664       batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 192)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 192)    0           soft_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4, 4, 384)    0           max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 4, 4, 384)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4, 4, 384)    0           activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6144)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 7)            43015       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,535,287\n",
      "Trainable params: 47,480,887\n",
      "Non-trainable params: 54,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WR0fUpy18vAZ"
   },
   "outputs": [],
   "source": [
    "opt1=tf.keras.optimizers.Adam(learning_rate=0.01,epsilon=0.1)\n",
    "model.compile(optimizer=opt1,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAf5ha295reS"
   },
   "outputs": [],
   "source": [
    "class_weights = {   \n",
    "                    0: 1.0,  # akiec\n",
    "                    1: 1.0,  # bcc\n",
    "                    2: 1.0,  # bkl\n",
    "                    3: 1.0,  # df\n",
    "                    4: 5.0,  # mel\n",
    "                    5: 1.0,  # nv\n",
    "                    6: 1.0,  # vasc\n",
    "                }\n",
    "\n",
    "\n",
    "checkpoint=  ModelCheckpoint(filepath = 'saved_model.hdf5',monitor='val_accuracy',save_best_only=True,save_weights_only=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUzTmiZ-8hL3",
    "outputId": "4e44981a-79c0-4387-c464-411635b8c95c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "836/836 - 267s - loss: 2.3987 - accuracy: 0.3666 - val_loss: 0.9806 - val_accuracy: 0.7221\n",
      "Epoch 2/150\n",
      "836/836 - 245s - loss: 1.8024 - accuracy: 0.4689 - val_loss: 0.9586 - val_accuracy: 0.7396\n",
      "Epoch 3/150\n",
      "836/836 - 245s - loss: 1.6301 - accuracy: 0.5100 - val_loss: 0.5338 - val_accuracy: 0.8236\n",
      "Epoch 4/150\n",
      "836/836 - 245s - loss: 1.4931 - accuracy: 0.5597 - val_loss: 0.6747 - val_accuracy: 0.7903\n",
      "Epoch 5/150\n",
      "836/836 - 245s - loss: 1.3880 - accuracy: 0.5806 - val_loss: 0.7115 - val_accuracy: 0.7251\n",
      "Epoch 6/150\n",
      "836/836 - 245s - loss: 1.3037 - accuracy: 0.6150 - val_loss: 0.7683 - val_accuracy: 0.7118\n",
      "Epoch 7/150\n",
      "836/836 - 245s - loss: 1.2046 - accuracy: 0.6444 - val_loss: 0.5758 - val_accuracy: 0.7837\n",
      "Epoch 8/150\n",
      "836/836 - 245s - loss: 1.1397 - accuracy: 0.6694 - val_loss: 0.3991 - val_accuracy: 0.8514\n",
      "Epoch 9/150\n",
      "836/836 - 245s - loss: 1.0791 - accuracy: 0.6867 - val_loss: 0.5498 - val_accuracy: 0.8121\n",
      "Epoch 10/150\n",
      "836/836 - 245s - loss: 0.9940 - accuracy: 0.7086 - val_loss: 0.5207 - val_accuracy: 0.8127\n",
      "Epoch 11/150\n",
      "836/836 - 245s - loss: 0.9716 - accuracy: 0.7218 - val_loss: 0.5023 - val_accuracy: 0.8079\n",
      "Epoch 12/150\n",
      "836/836 - 245s - loss: 0.9780 - accuracy: 0.7177 - val_loss: 0.5329 - val_accuracy: 0.8018\n",
      "Epoch 13/150\n",
      "836/836 - 245s - loss: 0.9052 - accuracy: 0.7374 - val_loss: 0.5127 - val_accuracy: 0.8012\n",
      "Epoch 14/150\n",
      "836/836 - 245s - loss: 0.8143 - accuracy: 0.7617 - val_loss: 0.3361 - val_accuracy: 0.8798\n",
      "Epoch 15/150\n",
      "836/836 - 245s - loss: 0.8229 - accuracy: 0.7654 - val_loss: 0.4407 - val_accuracy: 0.8556\n",
      "Epoch 16/150\n",
      "836/836 - 245s - loss: 0.7722 - accuracy: 0.7844 - val_loss: 0.3839 - val_accuracy: 0.8616\n",
      "Epoch 17/150\n",
      "836/836 - 244s - loss: 0.7292 - accuracy: 0.7952 - val_loss: 0.5959 - val_accuracy: 0.8405\n",
      "Epoch 18/150\n",
      "836/836 - 245s - loss: 0.6969 - accuracy: 0.7987 - val_loss: 0.4720 - val_accuracy: 0.8363\n",
      "Epoch 19/150\n",
      "836/836 - 245s - loss: 0.6822 - accuracy: 0.8008 - val_loss: 0.3199 - val_accuracy: 0.8828\n",
      "Epoch 20/150\n",
      "836/836 - 245s - loss: 0.6646 - accuracy: 0.8108 - val_loss: 0.3684 - val_accuracy: 0.8737\n",
      "Epoch 21/150\n",
      "836/836 - 244s - loss: 0.6492 - accuracy: 0.8211 - val_loss: 0.4893 - val_accuracy: 0.8320\n",
      "Epoch 22/150\n",
      "836/836 - 245s - loss: 0.6022 - accuracy: 0.8274 - val_loss: 0.4893 - val_accuracy: 0.8302\n",
      "Epoch 23/150\n",
      "836/836 - 245s - loss: 0.6196 - accuracy: 0.8263 - val_loss: 0.4393 - val_accuracy: 0.8471\n",
      "Epoch 24/150\n",
      "836/836 - 245s - loss: 0.5748 - accuracy: 0.8402 - val_loss: 0.3841 - val_accuracy: 0.8665\n",
      "Epoch 25/150\n",
      "836/836 - 245s - loss: 0.5411 - accuracy: 0.8463 - val_loss: 0.3820 - val_accuracy: 0.8604\n",
      "Epoch 26/150\n",
      "836/836 - 244s - loss: 0.5242 - accuracy: 0.8544 - val_loss: 0.4660 - val_accuracy: 0.8683\n",
      "Epoch 27/150\n",
      "836/836 - 244s - loss: 0.5280 - accuracy: 0.8516 - val_loss: 0.4863 - val_accuracy: 0.8363\n",
      "Epoch 28/150\n",
      "836/836 - 245s - loss: 0.4989 - accuracy: 0.8604 - val_loss: 0.5137 - val_accuracy: 0.8320\n",
      "Epoch 29/150\n",
      "836/836 - 249s - loss: 0.5579 - accuracy: 0.8456 - val_loss: 0.3692 - val_accuracy: 0.8713\n",
      "Epoch 30/150\n",
      "836/836 - 249s - loss: 0.4721 - accuracy: 0.8676 - val_loss: 0.7512 - val_accuracy: 0.7668\n",
      "Epoch 31/150\n",
      "836/836 - 249s - loss: 0.5349 - accuracy: 0.8575 - val_loss: 0.4194 - val_accuracy: 0.8610\n",
      "Epoch 32/150\n",
      "836/836 - 249s - loss: 0.4700 - accuracy: 0.8689 - val_loss: 0.4126 - val_accuracy: 0.8689\n",
      "Epoch 33/150\n",
      "836/836 - 249s - loss: 0.4011 - accuracy: 0.8908 - val_loss: 0.3526 - val_accuracy: 0.8864\n",
      "Epoch 34/150\n",
      "836/836 - 249s - loss: 0.3833 - accuracy: 0.8937 - val_loss: 0.6094 - val_accuracy: 0.8066\n",
      "Epoch 35/150\n",
      "836/836 - 247s - loss: 0.4339 - accuracy: 0.8774 - val_loss: 0.5302 - val_accuracy: 0.8012\n",
      "Epoch 36/150\n",
      "836/836 - 246s - loss: 0.4002 - accuracy: 0.8876 - val_loss: 0.3508 - val_accuracy: 0.8973\n",
      "Epoch 37/150\n",
      "836/836 - 249s - loss: 0.4147 - accuracy: 0.8834 - val_loss: 0.3293 - val_accuracy: 0.9027\n",
      "Epoch 38/150\n",
      "836/836 - 249s - loss: 0.3662 - accuracy: 0.8983 - val_loss: 0.3029 - val_accuracy: 0.9033\n",
      "Epoch 39/150\n",
      "836/836 - 249s - loss: 0.3547 - accuracy: 0.9042 - val_loss: 0.3409 - val_accuracy: 0.8864\n",
      "Epoch 40/150\n",
      "836/836 - 249s - loss: 0.3238 - accuracy: 0.9135 - val_loss: 0.5629 - val_accuracy: 0.8109\n",
      "Epoch 41/150\n",
      "836/836 - 249s - loss: 0.3285 - accuracy: 0.9114 - val_loss: 0.3705 - val_accuracy: 0.8731\n",
      "Epoch 42/150\n",
      "836/836 - 248s - loss: 0.3075 - accuracy: 0.9142 - val_loss: 0.3589 - val_accuracy: 0.8961\n",
      "Epoch 43/150\n",
      "836/836 - 245s - loss: 0.2882 - accuracy: 0.9173 - val_loss: 0.4122 - val_accuracy: 0.8955\n",
      "Epoch 44/150\n",
      "836/836 - 245s - loss: 0.3446 - accuracy: 0.9054 - val_loss: 0.3448 - val_accuracy: 0.8882\n",
      "Epoch 45/150\n",
      "836/836 - 245s - loss: 0.3557 - accuracy: 0.9048 - val_loss: 0.5422 - val_accuracy: 0.8689\n",
      "Epoch 46/150\n",
      "836/836 - 244s - loss: 0.3680 - accuracy: 0.9020 - val_loss: 0.3355 - val_accuracy: 0.8949\n",
      "Epoch 47/150\n",
      "836/836 - 245s - loss: 0.2945 - accuracy: 0.9232 - val_loss: 0.4331 - val_accuracy: 0.8665\n",
      "Epoch 48/150\n",
      "836/836 - 245s - loss: 0.2682 - accuracy: 0.9249 - val_loss: 0.4799 - val_accuracy: 0.8562\n",
      "Epoch 49/150\n",
      "836/836 - 244s - loss: 0.2962 - accuracy: 0.9219 - val_loss: 0.3306 - val_accuracy: 0.9063\n",
      "Epoch 50/150\n",
      "836/836 - 244s - loss: 0.2772 - accuracy: 0.9294 - val_loss: 0.3422 - val_accuracy: 0.9003\n",
      "Epoch 51/150\n",
      "836/836 - 245s - loss: 0.2578 - accuracy: 0.9280 - val_loss: 0.4370 - val_accuracy: 0.8683\n",
      "Epoch 52/150\n",
      "836/836 - 245s - loss: 0.2562 - accuracy: 0.9280 - val_loss: 0.3858 - val_accuracy: 0.8979\n",
      "Epoch 53/150\n",
      "836/836 - 244s - loss: 0.2456 - accuracy: 0.9312 - val_loss: 0.3388 - val_accuracy: 0.8924\n",
      "Epoch 54/150\n",
      "836/836 - 245s - loss: 0.2295 - accuracy: 0.9389 - val_loss: 0.4222 - val_accuracy: 0.8767\n",
      "Epoch 55/150\n",
      "836/836 - 245s - loss: 0.3243 - accuracy: 0.9115 - val_loss: 0.3663 - val_accuracy: 0.8828\n",
      "Epoch 56/150\n",
      "836/836 - 245s - loss: 0.2439 - accuracy: 0.9329 - val_loss: 0.3630 - val_accuracy: 0.9021\n",
      "Epoch 57/150\n",
      "836/836 - 245s - loss: 0.2577 - accuracy: 0.9335 - val_loss: 0.3823 - val_accuracy: 0.8949\n",
      "Epoch 58/150\n",
      "836/836 - 245s - loss: 0.2351 - accuracy: 0.9368 - val_loss: 0.4798 - val_accuracy: 0.8924\n",
      "Epoch 59/150\n",
      "836/836 - 245s - loss: 0.2380 - accuracy: 0.9370 - val_loss: 0.5046 - val_accuracy: 0.8701\n",
      "Epoch 60/150\n",
      "836/836 - 245s - loss: 0.2095 - accuracy: 0.9450 - val_loss: 0.3732 - val_accuracy: 0.9027\n",
      "Epoch 61/150\n",
      "836/836 - 245s - loss: 0.2149 - accuracy: 0.9434 - val_loss: 0.3372 - val_accuracy: 0.9003\n",
      "Epoch 62/150\n",
      "836/836 - 245s - loss: 0.1676 - accuracy: 0.9548 - val_loss: 0.4618 - val_accuracy: 0.8906\n",
      "Epoch 63/150\n",
      "836/836 - 246s - loss: 0.2007 - accuracy: 0.9455 - val_loss: 0.4865 - val_accuracy: 0.8876\n",
      "Epoch 64/150\n",
      "836/836 - 245s - loss: 0.2083 - accuracy: 0.9458 - val_loss: 0.4513 - val_accuracy: 0.8900\n",
      "Epoch 65/150\n",
      "836/836 - 246s - loss: 0.1814 - accuracy: 0.9500 - val_loss: 0.3618 - val_accuracy: 0.9148\n",
      "Epoch 66/150\n",
      "836/836 - 246s - loss: 0.1935 - accuracy: 0.9458 - val_loss: 0.4084 - val_accuracy: 0.8931\n",
      "Epoch 67/150\n",
      "836/836 - 245s - loss: 0.2258 - accuracy: 0.9386 - val_loss: 0.3302 - val_accuracy: 0.9112\n",
      "Epoch 68/150\n",
      "836/836 - 245s - loss: 0.1852 - accuracy: 0.9511 - val_loss: 0.3827 - val_accuracy: 0.9051\n"
     ]
    }
   ],
   "source": [
    "Earlystop = EarlyStopping(monitor='val_loss', mode='min',patience=30, min_delta=0.001)\n",
    "history = model.fit(train_batches,\n",
    "                    steps_per_epoch=(len(train_df)/batch_size),\n",
    "                    epochs=150,\n",
    "                    verbose=2,\n",
    "                    validation_data=test_batches,validation_steps=len(test_df)/batch_size,callbacks=[checkpoint,Earlystop],class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm_AewFBXTj8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"saved_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYxCDDjusR-S",
    "outputId": "9b1493cc-904c-4ffd-c96e-9253f3f1b8b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.69      0.49      0.57        45\n",
      "         bcc       0.83      0.75      0.79        53\n",
      "         bkl       0.72      0.78      0.75       132\n",
      "          df       0.71      0.42      0.53        12\n",
      "         mel       0.60      0.52      0.56        69\n",
      "          nv       0.96      0.97      0.97      1325\n",
      "        vasc       0.86      0.95      0.90        19\n",
      "\n",
      "    accuracy                           0.91      1655\n",
      "   macro avg       0.77      0.70      0.72      1655\n",
      "weighted avg       0.91      0.91      0.91      1655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "#getting the true labels per image \n",
    "y_true = test_batches.classes\n",
    "#getting the predicted labels per image \n",
    "y_prob=predictions\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = to_categorical(y_true)\n",
    "\n",
    "# Creating classification report \n",
    "report = classification_report(y_true, y_pred, target_names=targetnames)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yy59Zs1jqylz",
    "outputId": "21efa9a6-ef72-4e7b-b39a-3cd82f7276bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9114733088539252\n",
      "Recall: 0.9148036253776435\n",
      "Accuracy: 0.9148036253776435\n",
      "weighted Roc score: 0.9759700816942378\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"weighted Roc score: \" + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFRWOB82sDKi",
    "outputId": "fecfb555-6ee3-4312-b8fd-2ea25aed68bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7668679708170189\n",
      "Recall: 0.6976097177340648\n",
      "Accuracy: 0.9148036253776435\n",
      "Macro Roc score: 0.975123872974654\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='macro')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='macro')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"Macro Roc score: \" + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDNAPv9OsRVg",
    "outputId": "deef1de5-e55e-4e2d-9b67-800d02c0e5db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9148036253776435\n",
      "Recall: 0.9148036253776435\n",
      "Accuracy: 0.9148036253776435\n",
      "Micro Roc score: 0.9922556992603816\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='micro')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='micro')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "tpr={}\n",
    "fpr={}\n",
    "roc_auc={}\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_prob.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "print(\"Micro Roc score: \" + str(roc_auc[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U03sRDM2sudx",
    "outputId": "bb63779d-45f0-4517-ceb0-e98567566d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC score of akiec is: 0.9723809523809523\n",
      "The ROC AUC score of bcc is: 0.9951829081572563\n",
      "The ROC AUC score of bkl is: 0.9608776537535566\n",
      "The ROC AUC score of df is: 0.9892980320551836\n",
      "The ROC AUC score of mel is: 0.9468995010691375\n",
      "The ROC AUC score of nv is: 0.9781177815894797\n",
      "The ROC AUC score of vasc is: 0.983110281817012\n"
     ]
    }
   ],
   "source": [
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(7):\n",
    "    r = roc_auc_score(y_test[:, i], y_prob[:, i])\n",
    "    print(\"The ROC AUC score of \"+targetnames[i]+\" is: \"+str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5nG-b11wkep"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = dict()\n",
    "for i in range(7):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i], drop_intermediate=False)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "9wz2--WDwHQ4",
    "outputId": "1025ad57-b9a7-4cc1-df30-975bef9967d3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(fpr[0], tpr[0],'v-',label='akiec: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot(fpr[1], tpr[1],'c',label='bcc: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot(fpr[2], tpr[2],'b',label='bkl: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot(fpr[3], tpr[3],'g',label='df: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
    "plt.plot(fpr[4], tpr[4],'y',label='mel: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
    "plt.plot(fpr[5], tpr[5],'o-',label='nv: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
    "plt.plot(fpr[6], tpr[6],'r',label='vasc: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic of %s'%targetnames[i])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "IRV2+SA_30split.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
