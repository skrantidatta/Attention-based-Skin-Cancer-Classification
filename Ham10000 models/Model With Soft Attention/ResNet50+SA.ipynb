{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50+SA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5X3ASNLkv3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e7e2dd-4c4c-4702-fc63-1576af3d7f93"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTi0RAUGEfoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b05ca6-0ebd-4ce0-926b-512e8122501f"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "filename=\"/content/drive/My Drive/HAM10000.zip\"\n",
        "with ZipFile(filename,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"done\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa36bMKLze3z"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer,InputSpec\n",
        "import keras.layers as kl\n",
        "from glob import glob\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras import callbacks \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from  matplotlib import pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n",
        "%matplotlib inline\n",
        "import shutil\n",
        "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
        "from tensorflow.python.platform import build_info as tf_build_info\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lnzRzk7e44HL",
        "outputId": "6d1e2d2f-1669-42a6-f6a7-45a52b73ce41"
      },
      "source": [
        "data_pd = pd.read_csv('/content/drive/MyDrive/HAM10000_metadata.csv')\n",
        "data_pd.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlR6SjeEzXsm"
      },
      "source": [
        "train_dir = os.path.join('HAM10000', 'train_dir')\n",
        "test_dir = os.path.join('HAM10000', 'test_dir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "_IFqPgUu5jPj",
        "outputId": "979e5d51-8319-435c-f4db-1981b452c849"
      },
      "source": [
        "df_count = data_pd.groupby('lesion_id').count()\n",
        "df_count.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lesion_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HAM_0000000</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HAM_0000001</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HAM_0000002</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HAM_0000003</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HAM_0000004</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             image_id  dx  dx_type  age  sex  localization\n",
              "lesion_id                                                 \n",
              "HAM_0000000         2   2        2    2    2             2\n",
              "HAM_0000001         1   1        1    1    1             1\n",
              "HAM_0000002         3   3        3    3    3             3\n",
              "HAM_0000003         1   1        1    1    1             1\n",
              "HAM_0000004         1   1        1    1    1             1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjMQNZRI2xl7"
      },
      "source": [
        "df_count = df_count[df_count['dx'] == 1]\n",
        "df_count.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeVfs-Ly95gs"
      },
      "source": [
        "def duplicates(x):\n",
        "    unique = set(df_count['lesion_id'])\n",
        "    if x in unique:\n",
        "        return 'no' \n",
        "    else:\n",
        "        return 'duplicates'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WZZRSzO5v8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5042fd49-03f1-48a6-ed7b-ac849f1fe0c9"
      },
      "source": [
        "data_pd['is_duplicate'] = data_pd['lesion_id'].apply(duplicates)\n",
        "data_pd.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>duplicates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>duplicates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>duplicates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>duplicates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>duplicates</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization is_duplicate\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   duplicates\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   duplicates\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   duplicates\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   duplicates\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   duplicates"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BhGlAv0yAHu"
      },
      "source": [
        "df_count = data_pd[data_pd['is_duplicate'] == 'no']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3ndAO_Ex5fb"
      },
      "source": [
        "train, test_df = train_test_split(df_count, test_size=0.15, stratify=df_count['dx'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T7w2kYUdNkjX",
        "outputId": "5b6b9660-79f4-4fdb-ec79-4d5366f99a3e"
      },
      "source": [
        "def identify_trainOrtest(x):\n",
        "    test_data = set(test_df['image_id'])\n",
        "    if str(x) in test_data:\n",
        "        return 'test'\n",
        "    else:\n",
        "        return 'train'\n",
        "\n",
        "#creating train_df\n",
        "data_pd['train_test_split'] = data_pd['image_id'].apply(identify_trainOrtest)\n",
        "train_df = data_pd[data_pd['train_test_split'] == 'train']\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>train_test_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>duplicates</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>duplicates</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>duplicates</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>duplicates</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>duplicates</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx  ... localization  is_duplicate train_test_split\n",
              "0  HAM_0000118  ISIC_0027419  bkl  ...        scalp    duplicates            train\n",
              "1  HAM_0000118  ISIC_0025030  bkl  ...        scalp    duplicates            train\n",
              "2  HAM_0002730  ISIC_0026769  bkl  ...        scalp    duplicates            train\n",
              "3  HAM_0002730  ISIC_0025661  bkl  ...        scalp    duplicates            train\n",
              "4  HAM_0001466  ISIC_0031633  bkl  ...          ear    duplicates            train\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FPySEG1m58pu",
        "outputId": "18fd6e44-8d62-4a88-efa7-d29aa64637ae"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>HAM_0004931</td>\n",
              "      <td>ISIC_0026428</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>lower extremity</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6623</th>\n",
              "      <td>HAM_0001984</td>\n",
              "      <td>ISIC_0025092</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>trunk</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5908</th>\n",
              "      <td>HAM_0001664</td>\n",
              "      <td>ISIC_0025217</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>back</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4156</th>\n",
              "      <td>HAM_0005306</td>\n",
              "      <td>ISIC_0027056</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>60.0</td>\n",
              "      <td>male</td>\n",
              "      <td>back</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4579</th>\n",
              "      <td>HAM_0002478</td>\n",
              "      <td>ISIC_0031787</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>60.0</td>\n",
              "      <td>female</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        lesion_id      image_id  dx  ...     sex     localization is_duplicate\n",
              "5106  HAM_0004931  ISIC_0026428  nv  ...    male  lower extremity           no\n",
              "6623  HAM_0001984  ISIC_0025092  nv  ...    male            trunk           no\n",
              "5908  HAM_0001664  ISIC_0025217  nv  ...    male             back           no\n",
              "4156  HAM_0005306  ISIC_0027056  nv  ...    male             back           no\n",
              "4579  HAM_0002478  ISIC_0031787  nv  ...  female          unknown           no\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja7jQJQb39wi"
      },
      "source": [
        "# Image id of train and test images\n",
        "train_list = list(train_df['image_id'])\n",
        "test_list = list(test_df['image_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBJgBAjP13q5",
        "outputId": "463d1b3f-d77c-49b0-d89e-9ce5d21a47e0"
      },
      "source": [
        "len(test_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "828"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEChk1DK-H8Z",
        "outputId": "612e1f17-9db3-4dea-c99e-0b7aa5ee566a"
      },
      "source": [
        "len(train_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIoMqylGAYYZ"
      },
      "source": [
        "# Set the image_id as the index in data_pd\n",
        "data_pd.set_index('image_id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja_PtDYyDPMM"
      },
      "source": [
        "os.mkdir(train_dir)\n",
        "os.mkdir(test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsoqCvNsgmHP"
      },
      "source": [
        "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KYMTQugCmRR"
      },
      "source": [
        "for i in targetnames:\n",
        "  directory1=train_dir+'/'+i\n",
        "  directory2=test_dir+'/'+i\n",
        "  os.mkdir(directory1)\n",
        "  os.mkdir(directory2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL9vFa3X-ty1"
      },
      "source": [
        "for image in train_list:\n",
        "    file_name = image+'.jpg'\n",
        "    label = data_pd.loc[image, 'dx']\n",
        "\n",
        "    # path of source image \n",
        "    source = os.path.join('HAM10000', file_name)\n",
        "\n",
        "    # copying the image from the source to target file\n",
        "    target = os.path.join(train_dir, label, file_name)\n",
        "\n",
        "    shutil.copyfile(source, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwbKrEzJ_if2"
      },
      "source": [
        "for image in test_list:\n",
        "\n",
        "    file_name = image+'.jpg'\n",
        "    label = data_pd.loc[image, 'dx']\n",
        "\n",
        "    # path of source image \n",
        "    source = os.path.join('HAM10000', file_name)\n",
        "\n",
        "    # copying the image from the source to target file\n",
        "    target = os.path.join(test_dir, label, file_name)\n",
        "\n",
        "    shutil.copyfile(source, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W8hmE2OHjQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57e21fb-559b-40f8-8755-d8e45bd3e8a4"
      },
      "source": [
        "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "\n",
        "# Augmenting images and storing them in temporary directories \n",
        "for img_class in targetnames:\n",
        "\n",
        "    #creating temporary directories\n",
        "    # creating a base directory\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "    # creating a subdirectory inside the base directory for images of the same class\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "    img_list = os.listdir('HAM10000/train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir \n",
        "    for file_name in img_list:\n",
        "\n",
        "        # path of source image in training directory\n",
        "        source = os.path.join('HAM10000/train_dir/' + img_class, file_name)\n",
        "\n",
        "        # creating a target directory to send images \n",
        "        target = os.path.join(img_dir, file_name)\n",
        "\n",
        "        # copying the image from the source to target file\n",
        "        shutil.copyfile(source, target)\n",
        "\n",
        "    # Temporary augumented dataset directory.\n",
        "    source_path = aug_dir\n",
        "\n",
        "    # Augmented images will be saved to training directory\n",
        "    save_path = 'HAM10000/train_dir/' + img_class\n",
        "\n",
        "    # Creating Image Data Generator to augment images\n",
        "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='nearest'\n",
        "\n",
        "    )\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(source_path,save_to_dir=save_path,save_format='jpg',target_size=(224, 224),batch_size=batch_size)\n",
        "\n",
        "    # Generate the augmented images\n",
        "    aug_images = 8000 \n",
        "\n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((aug_images - num_files) / batch_size))\n",
        "\n",
        "    # creating 8000 augmented images per class\n",
        "    for i in range(0, num_batches):\n",
        "        images, labels = next(aug_datagen)\n",
        "\n",
        "    # delete temporary directory \n",
        "    shutil.rmtree('aug_dir')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 304 images belonging to 1 classes.\n",
            "Found 488 images belonging to 1 classes.\n",
            "Found 1033 images belonging to 1 classes.\n",
            "Found 109 images belonging to 1 classes.\n",
            "Found 1079 images belonging to 1 classes.\n",
            "Found 6042 images belonging to 1 classes.\n",
            "Found 132 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNisha_gM3_Z"
      },
      "source": [
        "train_path = 'HAM10000/train_dir'\n",
        "test_path = 'HAM10000/test_dir'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhQWqdRN79B3"
      },
      "source": [
        "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9_8FvOO7Rtu",
        "outputId": "7ca88c24-fda8-45d6-cb32-f3a43ae6ba5b"
      },
      "source": [
        "image_size = 224\n",
        "print(\"\\nTrain Batches: \")\n",
        "train_batches = datagen.flow_from_directory(directory=train_path,\n",
        "                                            target_size=(image_size,image_size),\n",
        "                                            batch_size=10,\n",
        "                                            shuffle=True)\n",
        "\n",
        "print(\"\\nTest Batches: \")\n",
        "test_batches =datagen.flow_from_directory(test_path,\n",
        "                                           target_size=(image_size,image_size),\n",
        "                                           batch_size=1,\n",
        "                                           shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Batches: \n",
            "Found 51699 images belonging to 7 classes.\n",
            "\n",
            "Test Batches: \n",
            "Found 828 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbwfHcsOPKYB"
      },
      "source": [
        "#Soft Attention\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer,InputSpec\n",
        "import keras.layers as kl\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "class SoftAttention(Layer):\n",
        "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
        "        self.channels=int(ch)\n",
        "        self.multiheads = m\n",
        "        self.aggregate_channels = aggregate\n",
        "        self.concat_input_with_scaled = concat_with_x\n",
        "\n",
        "        \n",
        "        super(SoftAttention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "\n",
        "        self.i_shape = input_shape\n",
        "\n",
        "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
        "    \n",
        "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
        "        \n",
        "        if self.aggregate_channels==False:\n",
        "\n",
        "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
        "        else:\n",
        "            if self.concat_input_with_scaled:\n",
        "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
        "            else:\n",
        "                self.out_features_shape = input_shape\n",
        "        \n",
        "\n",
        "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
        "                                        initializer='he_uniform',\n",
        "                                        name='kernel_conv3d')\n",
        "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
        "                                      initializer='zeros',\n",
        "                                      name='bias_conv3d')\n",
        "\n",
        "        super(SoftAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        exp_x = K.expand_dims(x,axis=-1)\n",
        "\n",
        "        c3d = K.conv3d(exp_x,\n",
        "                     kernel=self.kernel_conv3d,\n",
        "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
        "        conv3d = K.bias_add(c3d,\n",
        "                        self.bias_conv3d)\n",
        "        conv3d = kl.Activation('relu')(conv3d)\n",
        "\n",
        "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
        "\n",
        "        \n",
        "        conv3d = K.squeeze(conv3d, axis=-1)\n",
        "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
        "\n",
        "        softmax_alpha = K.softmax(conv3d, axis=-1) \n",
        "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
        "\n",
        "        \n",
        "        if self.aggregate_channels==False:\n",
        "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)       \n",
        "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
        "   \n",
        "            x_exp = K.expand_dims(x,axis=-2)\n",
        "   \n",
        "            u = kl.Multiply()([exp_softmax_alpha, x_exp])   \n",
        "  \n",
        "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
        "\n",
        "        else:\n",
        "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
        "\n",
        "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
        "\n",
        "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
        "\n",
        "            u = kl.Multiply()([exp_softmax_alpha, x])   \n",
        "\n",
        "        if self.concat_input_with_scaled:\n",
        "            o = kl.Concatenate(axis=-1)([u,x])\n",
        "        else:\n",
        "            o = u\n",
        "        \n",
        "        return [o, softmax_alpha]\n",
        "\n",
        "    def compute_output_shape(self, input_shape): \n",
        "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
        "\n",
        "    \n",
        "    def get_config(self):\n",
        "        return super(SoftAttention,self).get_config()\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrlJwba5By1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4112378c-a50b-4c15-a9f1-f326c4858b8b"
      },
      "source": [
        "resnet = tf.keras.applications.ResNet50(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        ")\n",
        "\n",
        "# Exclude the last 3 layers of the model.\n",
        "conv = resnet.layers[-3].output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTFfWfqXVjsf"
      },
      "source": [
        "Soft Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exrVTX_uVYPi"
      },
      "source": [
        "\n",
        "\n",
        "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
        "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
        "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
        "\n",
        "conv = concatenate([conv,attention_layer])\n",
        "conv  = Activation('relu')(conv)\n",
        "conv = Dropout(0.5)(conv)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R13YR5JxVpOg"
      },
      "source": [
        "\n",
        "output = GlobalAveragePooling2D()(conv)\n",
        "output = Dense(7, activation='softmax')(output)\n",
        "model = Model(inputs=resnet.input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD2GGKGNV23W",
        "outputId": "4cd0da4e-f481-4c16-f387-b04a26870f3a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "soft_attention (SoftAttention)  [(None, 7, 7, 2048), 294928      conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 2048)   0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 4, 4, 2048)   0           soft_attention[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4, 4, 4096)   0           max_pooling2d_1[0][0]            \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 4, 4, 4096)   0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 4, 4, 4096)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 4096)         0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 7)            28679       global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 23,911,319\n",
            "Trainable params: 23,858,199\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR0fUpy18vAZ"
      },
      "source": [
        "opt1=tf.keras.optimizers.Adam(learning_rate=0.01,epsilon=0.1)\n",
        "model.compile(optimizer=opt1,\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAf5ha295reS"
      },
      "source": [
        "class_weights = {   \n",
        "                    0: 1.0,  # akiec\n",
        "                    1: 1.0,  # bcc\n",
        "                    2: 1.0,  # bkl\n",
        "                    3: 1.0,  # df\n",
        "                    4: 5.0,  # mel\n",
        "                    5: 1.0,  # nv\n",
        "                    6: 1.0,  # vasc\n",
        "                }\n",
        "\n",
        "\n",
        "checkpoint=  ModelCheckpoint(filepath = 'ResNet50+SA.hdf5',monitor='val_accuracy',save_best_only=True,save_weights_only=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUzTmiZ-8hL3",
        "outputId": "a5667822-7ace-49da-f26b-896db54c720d"
      },
      "source": [
        "Earlystop = EarlyStopping(monitor='val_loss', mode='min',patience=40, min_delta=0.001)\n",
        "history = model.fit(train_batches,\n",
        "                    steps_per_epoch=(len(train_df)/10),\n",
        "                    epochs=300,\n",
        "                    verbose=2,\n",
        "                    validation_data=test_batches,validation_steps=len(test_df),callbacks=[checkpoint,Earlystop],class_weight=class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "919/919 - 113s - loss: 2.7689 - accuracy: 0.3341 - val_loss: 11.8405 - val_accuracy: 0.1908\n",
            "Epoch 2/300\n",
            "919/919 - 82s - loss: 2.1715 - accuracy: 0.3888 - val_loss: 15.2988 - val_accuracy: 0.1461\n",
            "Epoch 3/300\n",
            "919/919 - 82s - loss: 2.1700 - accuracy: 0.3790 - val_loss: 0.9258 - val_accuracy: 0.6981\n",
            "Epoch 4/300\n",
            "919/919 - 82s - loss: 1.7865 - accuracy: 0.4653 - val_loss: 0.8354 - val_accuracy: 0.6981\n",
            "Epoch 5/300\n",
            "919/919 - 81s - loss: 1.6130 - accuracy: 0.5074 - val_loss: 1.2128 - val_accuracy: 0.6304\n",
            "Epoch 6/300\n",
            "919/919 - 101s - loss: 1.5953 - accuracy: 0.5201 - val_loss: 0.6765 - val_accuracy: 0.7645\n",
            "Epoch 7/300\n",
            "919/919 - 82s - loss: 1.4805 - accuracy: 0.5516 - val_loss: 0.7194 - val_accuracy: 0.7790\n",
            "Epoch 8/300\n",
            "919/919 - 82s - loss: 1.3902 - accuracy: 0.5819 - val_loss: 1.3640 - val_accuracy: 0.5326\n",
            "Epoch 9/300\n",
            "919/919 - 82s - loss: 1.3620 - accuracy: 0.5935 - val_loss: 0.5446 - val_accuracy: 0.7923\n",
            "Epoch 10/300\n",
            "919/919 - 82s - loss: 1.3156 - accuracy: 0.6024 - val_loss: 0.5365 - val_accuracy: 0.8152\n",
            "Epoch 11/300\n",
            "919/919 - 82s - loss: 1.2907 - accuracy: 0.6100 - val_loss: 0.4532 - val_accuracy: 0.8273\n",
            "Epoch 12/300\n",
            "919/919 - 81s - loss: 1.2294 - accuracy: 0.6269 - val_loss: 0.5771 - val_accuracy: 0.7681\n",
            "Epoch 13/300\n",
            "919/919 - 82s - loss: 1.1767 - accuracy: 0.6427 - val_loss: 0.4983 - val_accuracy: 0.8152\n",
            "Epoch 14/300\n",
            "919/919 - 81s - loss: 1.1376 - accuracy: 0.6577 - val_loss: 0.4682 - val_accuracy: 0.8430\n",
            "Epoch 15/300\n",
            "919/919 - 81s - loss: 1.1269 - accuracy: 0.6595 - val_loss: 0.4569 - val_accuracy: 0.8478\n",
            "Epoch 16/300\n",
            "919/919 - 81s - loss: 1.1162 - accuracy: 0.6624 - val_loss: 0.5846 - val_accuracy: 0.8370\n",
            "Epoch 17/300\n",
            "919/919 - 81s - loss: 1.0421 - accuracy: 0.6865 - val_loss: 0.7716 - val_accuracy: 0.7295\n",
            "Epoch 18/300\n",
            "919/919 - 81s - loss: 1.0546 - accuracy: 0.6878 - val_loss: 0.5865 - val_accuracy: 0.7814\n",
            "Epoch 19/300\n",
            "919/919 - 82s - loss: 0.9936 - accuracy: 0.7002 - val_loss: 0.4029 - val_accuracy: 0.8647\n",
            "Epoch 20/300\n",
            "919/919 - 81s - loss: 1.0135 - accuracy: 0.6989 - val_loss: 0.4201 - val_accuracy: 0.8394\n",
            "Epoch 21/300\n",
            "919/919 - 82s - loss: 0.9824 - accuracy: 0.7015 - val_loss: 0.5176 - val_accuracy: 0.8333\n",
            "Epoch 22/300\n",
            "919/919 - 81s - loss: 0.9458 - accuracy: 0.7114 - val_loss: 0.4339 - val_accuracy: 0.8406\n",
            "Epoch 23/300\n",
            "919/919 - 81s - loss: 0.9255 - accuracy: 0.7250 - val_loss: 0.4744 - val_accuracy: 0.8104\n",
            "Epoch 24/300\n",
            "919/919 - 82s - loss: 0.9112 - accuracy: 0.7281 - val_loss: 0.5721 - val_accuracy: 0.8056\n",
            "Epoch 25/300\n",
            "919/919 - 82s - loss: 0.8530 - accuracy: 0.7445 - val_loss: 0.7406 - val_accuracy: 0.7705\n",
            "Epoch 26/300\n",
            "919/919 - 82s - loss: 0.8813 - accuracy: 0.7381 - val_loss: 0.4089 - val_accuracy: 0.8466\n",
            "Epoch 27/300\n",
            "919/919 - 82s - loss: 0.8690 - accuracy: 0.7405 - val_loss: 0.3587 - val_accuracy: 0.8696\n",
            "Epoch 28/300\n",
            "919/919 - 82s - loss: 0.8164 - accuracy: 0.7551 - val_loss: 0.3962 - val_accuracy: 0.8454\n",
            "Epoch 29/300\n",
            "919/919 - 82s - loss: 0.7819 - accuracy: 0.7675 - val_loss: 0.3686 - val_accuracy: 0.8696\n",
            "Epoch 30/300\n",
            "919/919 - 82s - loss: 0.7965 - accuracy: 0.7682 - val_loss: 0.3938 - val_accuracy: 0.8671\n",
            "Epoch 31/300\n",
            "919/919 - 82s - loss: 0.8104 - accuracy: 0.7590 - val_loss: 0.3499 - val_accuracy: 0.8756\n",
            "Epoch 32/300\n",
            "919/919 - 82s - loss: 0.7245 - accuracy: 0.7823 - val_loss: 0.5334 - val_accuracy: 0.7923\n",
            "Epoch 33/300\n",
            "919/919 - 82s - loss: 0.7523 - accuracy: 0.7814 - val_loss: 0.4013 - val_accuracy: 0.8684\n",
            "Epoch 34/300\n",
            "919/919 - 82s - loss: 0.7080 - accuracy: 0.7854 - val_loss: 0.5852 - val_accuracy: 0.7923\n",
            "Epoch 35/300\n",
            "919/919 - 82s - loss: 0.6766 - accuracy: 0.8004 - val_loss: 0.4268 - val_accuracy: 0.8647\n",
            "Epoch 36/300\n",
            "919/919 - 82s - loss: 0.6534 - accuracy: 0.8127 - val_loss: 0.4775 - val_accuracy: 0.8333\n",
            "Epoch 37/300\n",
            "919/919 - 82s - loss: 0.6677 - accuracy: 0.8032 - val_loss: 0.3457 - val_accuracy: 0.8889\n",
            "Epoch 38/300\n",
            "919/919 - 82s - loss: 0.6621 - accuracy: 0.8075 - val_loss: 0.6169 - val_accuracy: 0.8176\n",
            "Epoch 39/300\n",
            "919/919 - 82s - loss: 0.7004 - accuracy: 0.7951 - val_loss: 0.4171 - val_accuracy: 0.8611\n",
            "Epoch 40/300\n",
            "919/919 - 82s - loss: 0.6607 - accuracy: 0.8052 - val_loss: 0.4414 - val_accuracy: 0.8587\n",
            "Epoch 41/300\n",
            "919/919 - 82s - loss: 0.6188 - accuracy: 0.8151 - val_loss: 0.3434 - val_accuracy: 0.8937\n",
            "Epoch 42/300\n",
            "919/919 - 82s - loss: 0.5899 - accuracy: 0.8299 - val_loss: 0.4590 - val_accuracy: 0.8563\n",
            "Epoch 43/300\n",
            "919/919 - 82s - loss: 0.5805 - accuracy: 0.8295 - val_loss: 0.3583 - val_accuracy: 0.8877\n",
            "Epoch 44/300\n",
            "919/919 - 82s - loss: 0.5522 - accuracy: 0.8404 - val_loss: 0.4948 - val_accuracy: 0.8563\n",
            "Epoch 45/300\n",
            "919/919 - 82s - loss: 0.5710 - accuracy: 0.8322 - val_loss: 0.4478 - val_accuracy: 0.8708\n",
            "Epoch 46/300\n",
            "919/919 - 82s - loss: 0.5213 - accuracy: 0.8529 - val_loss: 0.3734 - val_accuracy: 0.8816\n",
            "Epoch 47/300\n",
            "919/919 - 82s - loss: 0.5077 - accuracy: 0.8501 - val_loss: 0.4154 - val_accuracy: 0.8635\n",
            "Epoch 48/300\n",
            "919/919 - 82s - loss: 0.5104 - accuracy: 0.8494 - val_loss: 0.3445 - val_accuracy: 0.8949\n",
            "Epoch 49/300\n",
            "919/919 - 82s - loss: 0.5270 - accuracy: 0.8472 - val_loss: 0.3405 - val_accuracy: 0.8756\n",
            "Epoch 50/300\n",
            "919/919 - 82s - loss: 0.4854 - accuracy: 0.8594 - val_loss: 0.3347 - val_accuracy: 0.8937\n",
            "Epoch 51/300\n",
            "919/919 - 82s - loss: 0.4489 - accuracy: 0.8657 - val_loss: 0.3905 - val_accuracy: 0.8973\n",
            "Epoch 52/300\n",
            "919/919 - 81s - loss: 0.4743 - accuracy: 0.8629 - val_loss: 0.3529 - val_accuracy: 0.8780\n",
            "Epoch 53/300\n",
            "919/919 - 82s - loss: 0.4706 - accuracy: 0.8622 - val_loss: 0.4430 - val_accuracy: 0.8478\n",
            "Epoch 54/300\n",
            "919/919 - 82s - loss: 0.4530 - accuracy: 0.8705 - val_loss: 0.3387 - val_accuracy: 0.8841\n",
            "Epoch 55/300\n",
            "919/919 - 82s - loss: 0.4514 - accuracy: 0.8702 - val_loss: 0.4329 - val_accuracy: 0.8744\n",
            "Epoch 56/300\n",
            "919/919 - 82s - loss: 0.4589 - accuracy: 0.8689 - val_loss: 0.4405 - val_accuracy: 0.8768\n",
            "Epoch 57/300\n",
            "919/919 - 81s - loss: 0.4373 - accuracy: 0.8736 - val_loss: 0.3375 - val_accuracy: 0.8865\n",
            "Epoch 58/300\n",
            "919/919 - 82s - loss: 0.4022 - accuracy: 0.8855 - val_loss: 0.4373 - val_accuracy: 0.8647\n",
            "Epoch 59/300\n",
            "919/919 - 82s - loss: 0.4079 - accuracy: 0.8817 - val_loss: 0.3562 - val_accuracy: 0.8865\n",
            "Epoch 60/300\n",
            "919/919 - 82s - loss: 0.3918 - accuracy: 0.8853 - val_loss: 0.3496 - val_accuracy: 0.8913\n",
            "Epoch 61/300\n",
            "919/919 - 82s - loss: 0.3970 - accuracy: 0.8877 - val_loss: 0.3432 - val_accuracy: 0.8937\n",
            "Epoch 62/300\n",
            "919/919 - 82s - loss: 0.3681 - accuracy: 0.8931 - val_loss: 0.3467 - val_accuracy: 0.8816\n",
            "Epoch 63/300\n",
            "919/919 - 82s - loss: 0.3828 - accuracy: 0.8877 - val_loss: 0.3579 - val_accuracy: 0.9010\n",
            "Epoch 64/300\n",
            "919/919 - 82s - loss: 0.3655 - accuracy: 0.8987 - val_loss: 0.3720 - val_accuracy: 0.8901\n",
            "Epoch 65/300\n",
            "919/919 - 82s - loss: 0.3601 - accuracy: 0.8953 - val_loss: 0.3527 - val_accuracy: 0.8998\n",
            "Epoch 66/300\n",
            "919/919 - 82s - loss: 0.3477 - accuracy: 0.8974 - val_loss: 0.4331 - val_accuracy: 0.8684\n",
            "Epoch 67/300\n",
            "919/919 - 81s - loss: 0.3495 - accuracy: 0.9001 - val_loss: 0.3950 - val_accuracy: 0.8684\n",
            "Epoch 68/300\n",
            "919/919 - 81s - loss: 0.3618 - accuracy: 0.8999 - val_loss: 0.3605 - val_accuracy: 0.8901\n",
            "Epoch 69/300\n",
            "919/919 - 82s - loss: 0.3200 - accuracy: 0.9082 - val_loss: 0.3563 - val_accuracy: 0.8949\n",
            "Epoch 70/300\n",
            "919/919 - 81s - loss: 0.3417 - accuracy: 0.9011 - val_loss: 0.3321 - val_accuracy: 0.8901\n",
            "Epoch 71/300\n",
            "919/919 - 81s - loss: 0.3353 - accuracy: 0.9012 - val_loss: 0.3966 - val_accuracy: 0.8696\n",
            "Epoch 72/300\n",
            "919/919 - 82s - loss: 0.3395 - accuracy: 0.9065 - val_loss: 0.4150 - val_accuracy: 0.8708\n",
            "Epoch 73/300\n",
            "919/919 - 82s - loss: 0.2951 - accuracy: 0.9128 - val_loss: 0.3225 - val_accuracy: 0.9022\n",
            "Epoch 74/300\n",
            "919/919 - 82s - loss: 0.2977 - accuracy: 0.9200 - val_loss: 0.3919 - val_accuracy: 0.8792\n",
            "Epoch 75/300\n",
            "919/919 - 82s - loss: 0.3009 - accuracy: 0.9146 - val_loss: 0.4311 - val_accuracy: 0.8756\n",
            "Epoch 76/300\n",
            "919/919 - 82s - loss: 0.2898 - accuracy: 0.9172 - val_loss: 0.3204 - val_accuracy: 0.8998\n",
            "Epoch 77/300\n",
            "919/919 - 82s - loss: 0.2489 - accuracy: 0.9275 - val_loss: 0.3413 - val_accuracy: 0.8998\n",
            "Epoch 78/300\n",
            "919/919 - 82s - loss: 0.2592 - accuracy: 0.9238 - val_loss: 0.3566 - val_accuracy: 0.8913\n",
            "Epoch 79/300\n",
            "919/919 - 82s - loss: 0.2654 - accuracy: 0.9245 - val_loss: 0.3590 - val_accuracy: 0.8986\n",
            "Epoch 80/300\n",
            "919/919 - 82s - loss: 0.2522 - accuracy: 0.9281 - val_loss: 0.3620 - val_accuracy: 0.9046\n",
            "Epoch 81/300\n",
            "919/919 - 82s - loss: 0.2717 - accuracy: 0.9252 - val_loss: 0.3918 - val_accuracy: 0.8768\n",
            "Epoch 82/300\n",
            "919/919 - 82s - loss: 0.2298 - accuracy: 0.9323 - val_loss: 0.3482 - val_accuracy: 0.8901\n",
            "Epoch 83/300\n",
            "919/919 - 82s - loss: 0.2430 - accuracy: 0.9321 - val_loss: 0.5819 - val_accuracy: 0.8200\n",
            "Epoch 84/300\n",
            "919/919 - 82s - loss: 0.2385 - accuracy: 0.9315 - val_loss: 0.4141 - val_accuracy: 0.9022\n",
            "Epoch 85/300\n",
            "919/919 - 82s - loss: 0.2552 - accuracy: 0.9267 - val_loss: 0.3782 - val_accuracy: 0.9010\n",
            "Epoch 86/300\n",
            "919/919 - 82s - loss: 0.2386 - accuracy: 0.9322 - val_loss: 0.3891 - val_accuracy: 0.8853\n",
            "Epoch 87/300\n",
            "919/919 - 82s - loss: 0.2365 - accuracy: 0.9357 - val_loss: 0.4671 - val_accuracy: 0.8659\n",
            "Epoch 88/300\n",
            "919/919 - 82s - loss: 0.2636 - accuracy: 0.9271 - val_loss: 0.4297 - val_accuracy: 0.8708\n",
            "Epoch 89/300\n",
            "919/919 - 82s - loss: 0.2472 - accuracy: 0.9284 - val_loss: 0.4187 - val_accuracy: 0.8841\n",
            "Epoch 90/300\n",
            "919/919 - 82s - loss: 0.2338 - accuracy: 0.9339 - val_loss: 0.3416 - val_accuracy: 0.9010\n",
            "Epoch 91/300\n",
            "919/919 - 82s - loss: 0.2402 - accuracy: 0.9300 - val_loss: 0.3859 - val_accuracy: 0.8937\n",
            "Epoch 92/300\n",
            "919/919 - 82s - loss: 0.2113 - accuracy: 0.9415 - val_loss: 0.4899 - val_accuracy: 0.8925\n",
            "Epoch 93/300\n",
            "919/919 - 82s - loss: 0.2174 - accuracy: 0.9367 - val_loss: 0.4692 - val_accuracy: 0.8901\n",
            "Epoch 94/300\n",
            "919/919 - 82s - loss: 0.2095 - accuracy: 0.9413 - val_loss: 0.3604 - val_accuracy: 0.8986\n",
            "Epoch 95/300\n",
            "919/919 - 82s - loss: 0.1961 - accuracy: 0.9434 - val_loss: 0.3452 - val_accuracy: 0.8913\n",
            "Epoch 96/300\n",
            "919/919 - 82s - loss: 0.1704 - accuracy: 0.9475 - val_loss: 0.3919 - val_accuracy: 0.8925\n",
            "Epoch 97/300\n",
            "919/919 - 82s - loss: 0.1914 - accuracy: 0.9468 - val_loss: 0.4695 - val_accuracy: 0.8841\n",
            "Epoch 98/300\n",
            "919/919 - 82s - loss: 0.1702 - accuracy: 0.9533 - val_loss: 0.3976 - val_accuracy: 0.8998\n",
            "Epoch 99/300\n",
            "919/919 - 82s - loss: 0.1585 - accuracy: 0.9559 - val_loss: 0.3989 - val_accuracy: 0.8986\n",
            "Epoch 100/300\n",
            "919/919 - 82s - loss: 0.1685 - accuracy: 0.9505 - val_loss: 0.4225 - val_accuracy: 0.9034\n",
            "Epoch 101/300\n",
            "919/919 - 82s - loss: 0.1428 - accuracy: 0.9585 - val_loss: 0.4656 - val_accuracy: 0.8961\n",
            "Epoch 102/300\n",
            "919/919 - 82s - loss: 0.1723 - accuracy: 0.9496 - val_loss: 0.3985 - val_accuracy: 0.8986\n",
            "Epoch 103/300\n",
            "919/919 - 82s - loss: 0.1915 - accuracy: 0.9455 - val_loss: 0.3926 - val_accuracy: 0.8973\n",
            "Epoch 104/300\n",
            "919/919 - 82s - loss: 0.1468 - accuracy: 0.9558 - val_loss: 0.3752 - val_accuracy: 0.8986\n",
            "Epoch 105/300\n",
            "919/919 - 82s - loss: 0.1441 - accuracy: 0.9583 - val_loss: 0.4851 - val_accuracy: 0.9010\n",
            "Epoch 106/300\n",
            "919/919 - 82s - loss: 0.1976 - accuracy: 0.9467 - val_loss: 0.4094 - val_accuracy: 0.9022\n",
            "Epoch 107/300\n",
            "919/919 - 82s - loss: 0.1421 - accuracy: 0.9603 - val_loss: 0.5018 - val_accuracy: 0.8563\n",
            "Epoch 108/300\n",
            "919/919 - 82s - loss: 0.1991 - accuracy: 0.9436 - val_loss: 0.5002 - val_accuracy: 0.8514\n",
            "Epoch 109/300\n",
            "919/919 - 82s - loss: 0.1628 - accuracy: 0.9530 - val_loss: 0.4381 - val_accuracy: 0.8804\n",
            "Epoch 110/300\n",
            "919/919 - 82s - loss: 0.1513 - accuracy: 0.9570 - val_loss: 0.3710 - val_accuracy: 0.9155\n",
            "Epoch 111/300\n",
            "919/919 - 82s - loss: 0.1326 - accuracy: 0.9625 - val_loss: 0.4129 - val_accuracy: 0.8949\n",
            "Epoch 112/300\n",
            "919/919 - 82s - loss: 0.1371 - accuracy: 0.9607 - val_loss: 0.4336 - val_accuracy: 0.8937\n",
            "Epoch 113/300\n",
            "919/919 - 82s - loss: 0.1407 - accuracy: 0.9632 - val_loss: 0.4149 - val_accuracy: 0.8973\n",
            "Epoch 114/300\n",
            "919/919 - 82s - loss: 0.1250 - accuracy: 0.9643 - val_loss: 0.3751 - val_accuracy: 0.9034\n",
            "Epoch 115/300\n",
            "919/919 - 82s - loss: 0.1263 - accuracy: 0.9635 - val_loss: 0.4285 - val_accuracy: 0.9070\n",
            "Epoch 116/300\n",
            "919/919 - 82s - loss: 0.1364 - accuracy: 0.9629 - val_loss: 0.4868 - val_accuracy: 0.8853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm_AewFBXTj8"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "model.load_weights(\"ResNet50+SA.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO8IxF0er88T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2863fc32-35e7-4d47-8b42-c8fc81dbafde"
      },
      "source": [
        "predictions = model.predict(test_batches, steps=len(test_df), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "828/828 [==============================] - 11s 13ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYxCDDjusR-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb18a18-24d1-4093-9d9a-5ded9a857aa5"
      },
      "source": [
        "#geting predictions on test dataset\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "#getting the true labels per image \n",
        "y_true = test_batches.classes\n",
        "#getting the predicted labels per image \n",
        "y_prob=predictions\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_test = to_categorical(y_true)\n",
        "\n",
        "# Creating classification report \n",
        "report = classification_report(y_true, y_pred, target_names=targetnames)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.67      0.43      0.53        23\n",
            "         bcc       0.88      0.85      0.86        26\n",
            "         bkl       0.67      0.70      0.68        66\n",
            "          df       1.00      0.50      0.67         6\n",
            "         mel       0.73      0.47      0.57        34\n",
            "          nv       0.95      0.98      0.97       663\n",
            "        vasc       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.92       828\n",
            "   macro avg       0.84      0.69      0.75       828\n",
            "weighted avg       0.91      0.92      0.91       828\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy59Zs1jqylz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c314b88-35c9-460f-fcc6-b63a35fe0856"
      },
      "source": [
        "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
        "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
        "print(\"weighted Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='weighted')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.910628574970054\n",
            "Recall: 0.9154589371980676\n",
            "Accuracy: 0.9154589371980676\n",
            "weighted Roc score: 0.978602070200313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFRWOB82sDKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2ee6fe-be46-41d7-c3c6-5d42ce4725d7"
      },
      "source": [
        "\n",
        "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='macro')))\n",
        "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='macro')))\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
        "print(\"Macro Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.8417758397320441\n",
            "Recall: 0.6902718764611349\n",
            "Accuracy: 0.9154589371980676\n",
            "Macro Roc score: 0.9808875421592932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDNAPv9OsRVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ce7b00-a761-4c00-b456-26c75360b954"
      },
      "source": [
        "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='micro')))\n",
        "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='micro')))\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
        "tpr={}\n",
        "fpr={}\n",
        "roc_auc={}\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_prob.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "print(\"Micro Roc score: \" + str(roc_auc[\"micro\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9154589371980676\n",
            "Recall: 0.9154589371980676\n",
            "Accuracy: 0.9154589371980676\n",
            "Micro Roc score: 0.9944595896831508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U03sRDM2sudx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3634358-f415-457d-e2e3-2332be6055a5"
      },
      "source": [
        "fpr = {}\n",
        "tpr = {}\n",
        "roc_auc = {}\n",
        "for i in range(7):\n",
        "    r = roc_auc_score(y_test[:, i], y_prob[:, i])\n",
        "    print(\"The ROC AUC score of \"+targetnames[i]+\" is: \"+str(r))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The ROC AUC score of akiec is: 0.9814744801512287\n",
            "The ROC AUC score of bcc is: 0.9967389219259543\n",
            "The ROC AUC score of bkl is: 0.9648651873061322\n",
            "The ROC AUC score of df is: 0.9714111922141119\n",
            "The ROC AUC score of mel is: 0.9731441695065934\n",
            "The ROC AUC score of nv is: 0.9791900909547968\n",
            "The ROC AUC score of vasc is: 0.9993887530562346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5nG-b11wkep"
      },
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "roc_auc = dict()\n",
        "for i in range(7):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i], drop_intermediate=False)\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wz2--WDwHQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966c976d-ecca-452c-b393-464961781b50"
      },
      "source": [
        "\n",
        "plt.plot(fpr[0], tpr[0],'v-',label='akiec: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
        "plt.plot(fpr[1], tpr[1],'c',label='bcc: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
        "plt.plot(fpr[2], tpr[2],'b',label='bkl: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
        "plt.plot(fpr[3], tpr[3],'g',label='df: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
        "plt.plot(fpr[4], tpr[4],'y',label='mel: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
        "plt.plot(fpr[5], tpr[5],'o-',label='nv: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
        "plt.plot(fpr[6], tpr[6],'r',label='vasc: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([-0.1, 1.1])\n",
        "plt.ylim([-0.1, 1.1])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic of %s'%targetnames[i])\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}